#set up the notebook
!pip install Biopython
from Bio import SeqIO
import numpy as np
import pandas as pd
from collections import Counter
import gdown
data_path = 'https://drive.google.com/uc?id=1PqupjbA0HYNs1fd1y6TAkkvZeMQ6kmK0'
cov2_vs_rtg13 = './SARS_CoV_2_vs_RTG13.fasta'
gdown.download(data_path, cov2_vs_rtg13, True)

!pip install Biopython
from Bio import SeqIO
import numpy as np
import pandas as pd
import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from collections import Counter
from sklearn import model_selection, linear_model
import gdown
data_path = 'https://drive.google.com/uc?id=1f1CtRwSohB7uaAypn8iA4oqdXlD_xXL1'
cov2_sequences = 'SARS_CoV_2_sequences_global.fasta'
gdown.download(data_path, cov2_sequences, True)

#a sequence of the SARS-CoV-2 genome 
sequences = [r for r in SeqIO.parse(cov2_sequences, 'fasta')]
sequence_num =  10#@param {type:"integer"}
print(sequences[sequence_num])

#how many sequences are there?
n_sequences = len(sequences) 
print("There are %.0f sequences" % n_sequences)    

#predicting the country a S-C-2 virus came from based on its genome:

# monitoring progress using the tqdm library
mutation_df = pd.DataFrame()
n_bases_in_seq = len(sequences[0])

# iterate though all positions in this sequence
for location in tqdm.tqdm(range(n_bases_in_seq)): 
  bases_at_location = np.array([s[location] for s in sequences])
  # if there are no mutations at this position, move on.
  if len(set(bases_at_location))==1: continue # If
  for base in ['A', 'T', 'G', 'C', '-']:
    feature_values = (bases_at_location==base)
    
    # set the values of any base that equals 'N' to np.nan
    feature_values[bases_at_location=='N'
                   ] = np.nan
    
    # convert from T/F to 0/1
    feature_values  = feature_values*1
    
    # make the column name look like <location>_<base> (1_A, 2_G, 3_A, etc)
    column_name = str(location) + '_' + base
    mutation_df[column_name] = feature_values

# print size of the feature matrix/table
n_rows = np.shape(mutation_df)[0]
n_columns = np.shape(mutation_df)[1]
print("Size of matrix: %i rows x %i columns" %(n_rows, n_columns))

# what matrix looks like:
mutation_df.head()

#the different number of samples that come from each country.**
country = "Taiwan" #@param dict_keys(['China', 'Kazakhstan', 'India', 'Sri Lanka', 'Taiwan', 'Hong Kong', 'Viet Nam', 'Thailand', 'Nepal', 'Israel', 'South Korea', 'Iran', 'Pakistan', 'Turkey', 'Australia', 'USA']
countries = [(s.description).split('|')[-1] for s in sequences]
print("There are %i sequences from %s." %
      (Counter(countries)[country], country))
      
mutation_df = pd.DataFrame()
n_bases_in_seq = len(sequences[0])

# Iterate though all positions in this sequence.
for location in tqdm.tqdm(range(n_bases_in_seq)): # tqdm is a nice library that prints our progress.
  bases_at_location = np.array([s[location] for s in sequences])
  # If there are no mutations at this position, move on.
  if len(set(bases_at_location))==1: continue # If
  for base in ['A', 'T', 'G', 'C', '-']:
    feature_values = (bases_at_location==base)
    
    
    # Set the values of any base that equals 'N' to np.nan.
    feature_values[bases_at_location=='N'
                   ] = np.nan
    
    # Convert from T/F to 0/1.
    feature_values  = feature_values*1
    
    # Make the column name look like <location>_<base> (1_A, 2_G, 3_A, etc.)
    column_name = str(location) + '_' + base
    mutation_df[column_name] = feature_values

# Print the size of the feature matrix/table.
n_rows = np.shape(mutation_df)[0]
n_columns = np.shape(mutation_df)[1]
print("Size of matrix: %i rows x %i columns" %(n_rows, n_columns))

# Check what the matrix looks like:
mutation_df.head()

#convering country to region
countries_to_regions_dict = {
         'Australia': 'Oceania',
         'China': 'Asia',
         'Hong Kong': 'Asia',
         'India': 'Asia',
         'Nepal': 'Asia',
         'South Korea': 'Asia',
         'Sri Lanka': 'Asia',
         'Taiwan': 'Asia',
         'Thailand': 'Asia',
         'USA': 'North America',
         'Viet Nam': 'Asia'
}

regions = [countries_to_regions_dict[c] if c in 
           countries_to_regions_dict else 'NA' for c in countries]
mutation_df['label'] = regions

#how many samples from each region
region = "Asia" #@param ['Oceania', 'North America', 'Asia']
print("There are %i sequences from %s." %
      (Counter(regions)[region], region))

#balanced data: a dataset with equal numbers of samples with each label
#this removes duplicate samples from the dataset and balances the samples.

balanced_df = mutation_df.copy()
balanced_df['label'] = regions
balanced_df = balanced_df[balanced_df.label!='NA']
balanced_df = balanced_df.drop_duplicates()
samples_north_america = balanced_df[balanced_df.label== 
                                    'North America']
samples_oceania = balanced_df[balanced_df.label== 
                              'Oceania']
samples_asia = balanced_df[balanced_df.label== 
                           'Asia']

# number of samples we will use from each region:
n = min(len(samples_north_america),
        len(samples_oceania),
        len(samples_asia))

balanced_df = pd.concat([samples_north_america[:n],
                    samples_asia[:n],
                    samples_oceania[:n]])
print("Number of samples in each region: ", Counter(balanced_df['label']))

#sets up x feature matrix and y label list from balanced_df. change values here
X = balanced_df.drop('label', 1)
Y = balanced_df.label
data = "X (features)" #@param ['X (features)', 'Y (label)']
start = 1 #@param {type:'integer'}
stop =  10#@param {type:'integer'}

if start>=stop:print("Start must be < stop!")
else:
  if data=='X (features)':
    print(X.iloc[start:stop])
  if data=='Y (label)':
    print(Y[start:stop])
    
#train model using standard pipeline 
lm = linear_model.LogisticRegression(
    multi_class="multinomial", max_iter=1000,
    fit_intercept=False, tol=0.001, solver='saga', random_state=42)

# split into training/testing set
X_train, X_test, Y_train, Y_test = model_selection.train_test_split(
    X, Y, train_size=.8)

# train/fit model:

#using confusion matrix to test model's performance
# predict on the test set
Y_pred = lm.predict(X_test)

# compute accuracy
accuracy = 100*np.mean(Y_pred==Y_test)
print("Accuracy: %", accuracy)

# compute confusion matrix
confusion_mat = pd.DataFrame(confusion_matrix(Y_test, Y_pred))
confusion_mat.columns = [c + ' predicted' for c in lm.classes_]
confusion_mat.index = [c + ' true' for c in lm.classes_]

print(confusion_mat)
lm.fit(X_train, Y_train)
